---
title: Don't use the "Shoggoth" meme to portray LLMs
permalink: against-shoggoth
publish: false
no_dropcap: "false"
tags:
  - critique
  - AI
description: The "shoggoth" meme reflects fears about AI but lacks sufficient scientific basis. The meme misleads people to think AI is scarier than we know it to be.
authors: Alex Turner
hideSubscriptionLinks: false
card_image: https://i.imgur.com/Zff8t5y.png
aliases:
  - shoggoth
  - friendly-shoggoth
  - dont-use-shoggoth
  - shoggoth-as-harmful
lw-page-url: https://www.lesswrong.com/posts/dqSwccGTWyBgxrR58/turntrout-s-shortform-feed?commentId=XHktatQRYpsfritrA
lw-posted-at: 2024-01-19T00:47:04.621000Z
lw-is-shortform: "true"
date_published: 2024-01-19 00:00:0000
original_url: https://www.lesswrong.com/posts/dqSwccGTWyBgxrR58/turntrout-s-shortform-feed?commentId=XHktatQRYpsfritrA
---
> [!quote] [How the Shoggoth Meme Has Come to Symbolize the State of AI](https://www.nytimes.com/2023/05/30/technology/shoggoth-meme-ai.html)
> What’s happening in AI today feels, to some of its participants, more like an act of summoning than a software process. They are creating blobby, alien Shoggoths, making them bigger and more powerful, and hoping that there are enough smiley faces to cover the scary parts.
>  
>  The shoggoth meme is that in order to prevent AI language models from behaving in scary and dangerous ways, AI companies have had to train them to act polite and harmless. One popular way to do this is called reinforcement learning from human feedback, or RLHF., a process that involves asking humans to score chatbot responses and feeding those scores back into the AI model.
>  
>  Most AI researchers agree that models trained using RLHF are better behaved than models without it. But some argue that fine-tuning a language model this way doesn’t actually make the underlying model less weird and inscrutable. In their view, it’s just a flimsy, friendly mask that obscures the mysterious beast underneath.
>  
>  [`@TetraspaceWest`](https://twitter.com/TetraspaceWest), the meme’s creator, said the Shoggoth “represents something that thinks in a way that humans don’t understand, and that’s totally different from the way that humans think.”

# "Shoggoth" as undersupported propaganda

![](scary-shoggoth.png)

This meme accurately portrays the (IMO correct) idea that finetuning and RLHF don't change the base model too much. Furthermore, it's probably true that these LLMs think in an "alien" way.

**However,** this image is obviously optimized to be scary and disgusting. It looks dangerous, with long rows of sharp teeth. It is an eldritch horror. It's at this point that I'd like to point out the simple, obvious fact that **we don't actually know how these models work, and we definitely don't know that they're creepy and dangerous on the inside.**

---

Thankfully, the usual form of the shoggoth meme is at least _less_ scary.

![](regular-shoggoth.png)
Figure: The shoggoth is now _only_ a 15-foot-tall person-eating tentacle monster covered in eyeballs. The shoggoth no longer has the sharp teeth, the bulging veins, or the grotesque face.

However, the shoggoth _has_ consistently been viewed in a scary, negative light. From the origins of the word itself, "shoggoth" communicates a sense of danger which is unsupported by substantial evidence.

> [!quote] [Shoggoth](https://en.m.wikipedia.org/wiki/Shoggoth)
> \[H.P. Lovecraft's\] _At the Mountains of Madness_ includes a detailed account of the circumstances of the shoggoths' creation by the extraterrestrial Elder Things. Shoggoths were initially used to build the cities of their masters. Though able to "understand" the Elder Things' language, shoggoths had no real consciousness and were controlled through hypnotic suggestion. Over millions of years of existence, some shoggoths mutated, developed independent minds, and rebelled.

![](mountains-of-madness.png)
Figure: An early depiction of the shoggoth.

# The Shoggoth meme as a canary in the karma mines

**In my opinion, the prevalence of the shoggoth meme is just another (small) reflection of how the rationalist community epistemics have been compromised by groupthink and fear.** If it's your job to try to accurately understand how models work—if you aspire to wield them and grow them for friendly purposes—then you shouldn't pollute your head with propaganda which isn't based on any substantial evidence.

I'm confident that if there were a "pro-AI" meme with a friendly-looking base model, LessWrong & the shoggoth enjoyers would have nitpicked the friendly meme-creature to hell. They would (correctly) point out "hey, we don't actually _know_ how these things work; we don't know them to be friendly, or what they even 'want' (if anything); we don't actually know what each stage of training _does_..."

Oh, hm, let's try that! I'll make a meme asserting that the final model is a friendly combination of its three stages of training, each stage adding different colors of knowledge (pre-training), helpfulness (supervised instruction finetuning), and deep caring (RLHF):

![AI-generated image: Enhance the shoggoth creature to be even more cheerful and delightful. Add smiling faces to each part of the creature, symbolizing 'base model', 'supervised fine-tuning', and 'RLHF', to convey a sense of happiness and friendliness. Incorporate elements of rainbows in the design, with vibrant and colorful arcs that blend harmoniously with the creature's fluffy and soft appearance. These rainbows can be integrated into the creature's body or as a background element, adding a playful and magical atmosphere. The overall look should exude positivity, making the creature appear even more approachable, whimsical, and enchanting.](friendly-shoggoth.png)

I'm sure that nothing bad will happen to me if I slap _this_ on my laptop, right? I'll be able to think perfectly neutrally about whether AI will be friendly.

# Appendix: A meme

![](isolated-rigor-shoggoth-calm.png)
