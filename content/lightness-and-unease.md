---
permalink: lightness-and-unease
lw-was-draft-post: 'false'
lw-is-af: 'false'
lw-is-debate: 'false'
lw-page-url: https://www.lesswrong.com/posts/EvKWNRkJgLosgRDSa/lightness-and-unease
lw-is-question: 'false'
lw-posted-at: 2018-03-21T05:24:26.289000Z
lw-last-modification: None
lw-curation-date: None
lw-frontpage-date: None
lw-was-unlisted: 'false'
lw-is-shortform: 'false'
lw-num-comments-on-upload: 2
lw-base-score: 31
lw-vote-count: 22
af-base-score: 9
af-num-comments-on-upload: 0
publish: true
title: Lightness and Unease
lw-latest-edit: 2018-03-21T05:24:26.289000Z
lw-is-linkpost: 'false'
tags:
aliases:
- lightness-and-unease
lw-sequence-title: Becoming Stronger
lw-sequence-image-grid: sequencesgrid/fkqj34glr5rquxm6z9sr
lw-sequence-image-banner: sequences/oerqovz6gvmcpq8jbabg
sequence-link: posts#becoming-stronger
prev-post-slug: set-theory-textbook-review
prev-post-title: "Set Up for Success: Insights from 'Naïve Set Theory'"
next-post-slug: AI-textbook-review
next-post-title: "The Art of the Artificial: Insights from 'Artificial Intelligence:
  A Modern Approach'"
lw-reward-post-warning: 'false'
use-full-width-images: 'false'
date_published: 03/21/2018
original_url: https://www.lesswrong.com/posts/EvKWNRkJgLosgRDSa/lightness-and-unease
skip_import: true
description: A personal reflection on finding the rationalist community and the joy
  and anxiety of pursuing AI alignment.
---
# Light

## Month 1

January 6th is the day I finished reading _Superintelligence_, and that’s the day my life felt like it entered protagonist mode. I tore through ten books over the next week and a half, from _The Art of Strategy_ to _Thinking: Fast and Slow_. I proceeded to finish the considerable remainder of the Sequences I’d left unread. It wasn’t fear that fueled me – it was a sweet blend of curiosity and protectiveness, about and for this cruel and beautiful world in which we live. It was a sense of the possibilities afforded to those lucky enough to live in what Scott Alexander dubbed the _carefree springtime of the universe_. It was a rekindling of my youthful inquisitiveness, when I’d spend afternoons lost in math books, coding a C++ text RPG, or caring for a caterpillar over its evolution, just to set it free.

## Month 2

I applied for the upcoming CFAR workshop and was later accepted (the interview was the first time where I heard another person say things like "updating"). I continued my non-technical reading, [summarized a technical alignment result](/toy-instrumental-convergence-paper-walkthrough), and [reviewed Naïve Set Theory](/set-theory-textbook-review). The concepts in that small set theory book expanded my mathematical horizons beyond measure (okay, I haven’t studied measure theory yet, so not _quite_ beyond measure). This is also when things really _clicked_ for me – I started [generating novel insights](/how-to-dissolve-it) regularly. Finally, I decided to [try for 5 minutes](https://www.readthesequences.com/UseTheTryHarderLuke) before giving up on my [CHAI application](http://humancompatible.ai/jobs); this led to an idea of which I am truly proud.

I do not yet know whether I will be accepted for CHAI’s internship, but the idea merits two posts of its own: one for the proposal itself, and one for the wonderful emotional and psychological process of discovery I experienced.

## Month 3

I find myself eagerly reading chapters and completing problem sets from _AI: A Modern Approach_, well beyond what is required for my class. I’m writing more often, learning more deeply, and generally my hedonic index is through the roof relative to last fall. I know I’ve given the impression of having let up over the last month, but I really haven’t – there are multiple projects of mine whose fruits I look forward to sharing.

## Forwards

I’ve noticed that I go through phases of intense interest in activities, commitments, and games – this shift tended to occur multiple times per year, but has slowed as I’ve matured. I don’t expect that to happen here. I sure hope it doesn’t – I’m not ready to relinquish this wonderful lightness, this eagerness to explore how the world _really_ works on a gears level, this internal sense of purpose.

This lightness does not appear to be conditional on future acceptance or recognition – even when imagining a world in which I know with certainty that no AI safety research group brings me into their fold, the light and curiosity remain.

I am so very grateful that I found this community.

# Decision

I remember the moment that was, in hindsight, a litmus test of my readiness. I was finishing the Sequences, and the reality of the “dark world” pressed down on me. My chest felt tight and pressed down upon, and gravity seemed so much _stronger_ than usual; the problems were **large**, and I felt small. Would this become an obsession that would consume my psyche and my studies? Where did I leave my hero license? Who was I to make this kind of status claim, to believe that I could make progress on problems of such importance?

I came to [Beyond the Reach of God](https://www.lesswrong.com/posts/sYgv4eYH82JEsTD34/beyond-the-reach-of-god) and I knew I had to decide. Someone close to me had advised me to step back, to remain in the shallows for a while longer – where I was tall enough to stand. I, however, was privy to information which they were not.

Trout can swim.

# Gnawing Shadows

I can sense a mix of reasonable dissatisfaction with my performance, and "psychologically unrealistic" expectations. I’ve taken far longer than I wished on my AI book; if only I were less vulnerable to [pica](http://lesswrong.com/lw/15w/experiential_pica/), if I studied an extra hour each day, if the concepts had come to me more easily… I imagine worlds in which I did better and had also made substantial progress in, say, topology or linear algebra by this point in time.

I’ve come so far, but I also am quite aware of [the levels above mine](https://www.readthesequences.com/TheLevelAboveMine). Sometimes it weighs on me, but usually I view the task before me with twisted pleasure.