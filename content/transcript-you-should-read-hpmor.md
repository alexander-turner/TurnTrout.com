---
permalink: read-hpmor
lw-was-draft-post: 'false'
lw-is-af: 'false'
lw-is-debate: 'false'
lw-page-url: 
  https://www.lesswrong.com/posts/HL6x8zHo9BkuK3tic/transcript-you-should-read-hpmor
lw-is-question: 'false'
lw-posted-at: 2021-11-02T18:20:53.161000Z
lw-last-modification: 2024-07-07T21:15:29.825000Z
lw-curation-date: None
lw-frontpage-date: 2021-11-02T18:57:09.142000Z
lw-was-unlisted: 'false'
lw-is-shortform: 'false'
lw-num-comments-on-upload: 12
lw-base-score: 124
lw-vote-count: 59
af-base-score: 34
af-num-comments-on-upload: 0
publish: true
title: You Should Read 'Harry Potter and the Methods of Rationality'
lw-latest-edit: 2023-08-27T21:04:29.890000Z
lw-is-linkpost: 'false'
tags:
- rationality
- fiction
aliases:
- transcript-you-should-read-hpmor
lw-reward-post-warning: 'false'
use-full-width-images: 'false'
date_published: 11/02/2021
original_url: 
  https://www.lesswrong.com/posts/HL6x8zHo9BkuK3tic/transcript-you-should-read-hpmor
skip_import: true
card_image: https://assets.turntrout.com/static/images/card_images/grinnell.png
description: Why you should read _Harry Potter and the Methods of Rationality_ to
  live more ethically and effectively.
---
> [!note]
> The following is the transcript of a talk I gave for some current computer science students at my alma mater, [Grinnell College](https://www.grinnell.edu/). This talk answers "What do I wish I had known while at Grinnell?".

![](https://assets.turntrout.com/static/images/posts/grinnell.avif)
Figure: Grinnell campus.

Hi, I'm Alex Turner. I’m honored to be here under Sam’s invitation. I'm in the class of 2016. I miss Grinnell, but I miss my friends more—enjoy the time you have left together. 

I’m going to give you the advice I would have given Alex<sub>2012</sub>. For some of you, this advice won’t resonate, and I think that’s OK. People are complicated, and I don’t even know most of you. I don’t pretend to have a magic tip that will benefit everyone here. But if I can make a big difference for one or two of you, I’ll be happy. 

I’m going to state my advice now. It’s going to sound silly. 

> [!idea] Recommendation
> You should read a Harry Potter fanfiction called [_Harry Potter and the Methods of Rationality_](https://cdn.jsdelivr.net/gh/rjl20/hpmor@0c10d2e8b6bd68e88fd2fc6e6b233140917e7314/out/hpmor.pdf) (HPMOR). 

I’m serious. The intended benefits can be gained in other ways, but HPMOR is the best way I know of. Let me explain.

---

When I was younger, I was operating under some kind of haze, a veil, distancing me from what I really would care about.

I responded to social customs and pressure, instead of figuring out what is good and right by my own lights, how to make that happen, and then executing. Usually it’s fine to just follow social expectations. But there are key moments in life where it’s important to reason on your own. 

At Grinnell, I exemplified a lot of values I now look down on. I was extremely motivated to do foolish or irrelevant things. I fought bravely for worthless side pursuits. I don’t even like driving, but I thought I wanted a fancy car. I was trapped in my own delusions because I wasn’t thinking properly. 

Why did this happen, and what do I think has changed? 

# On Caring

First, I was disconnected from what I would have really cared about upon honest, unflinching reflection. I thought I wanted Impressive Material Things. I thought I wanted a Respectable Life. I didn’t care about the bible, but I brought it with me to my dorm anyways so that I’d be more “wholesome” according to my cultural background. Chasing something someone convinced me to believe I wanted, but which I don’t care about. 

I became motivated to _unironically_ _reflect on what is good, how I want the universe to look by the time I’m done with it—to reason about what matters without asking for permission._ Not so that you can show how caring you are on social media. But because some things are _fucking important_. Peace, learning, freedom, health, justice. Human flourishing. Happiness. 

When I inhabit my old ways of thinking about altruism, they evoke guilt and concern: “The world will burn. I have to do my part.” If, however, I’ve discharged my duties by donating and recycling and such, then I no longer feel guilty. But the cruel fact is that _no matter what I do, millions of people will die of starvation this year_. Due to a coincidence of space and time, none of these people happen to be my brother or sister, my mother or father. None are starving two feet away from me. But who cares if someone starves two feet away, or 42 million feet away—they’re still starving! 

What I’m saying here is subtler than “care a lot.” I’m gesturing at a particular _kind_ of caring. The kind from the [assigned essay](https://forum.effectivealtruism.org/posts/hkimyETEo76hJ6NpW/on-caring?utm_sq=guavacgepf&utm_source=facebook&utm_medium=social&utm_campaign=effectivealtruism&utm_content=calltoactioninspire&fbclid=IwAR0q7gi4HzMJi4bxpIroWzd9CxnKhW5qbrxCyHkdF0-uFugQobk02p1_a8E). Since you all read it, I probably don’t need to explain further, but I will anyways. Some extreme altruists give almost everything they have to charity. It’s natural to assume they have stronger “caring” feelings than you do, but that may not be true. 

The truth is that I am biologically incapable of caring as much as _9 million × (how much I would care if my brother starved)_. My internal “caring system” doesn’t go up that many decibels, it just silently throws an emotion overflow error. Does that mean I can’t, or don't want to, dedicate my life to altruism? No. It means I ignore my uncalibrated emotions, that I do some math and science to estimate how I can make the biggest difference, and then do that. 

What does this have to do with Harry Potter? HPMOR made me realize I _should_ care in this way. HPMOR let me _experience the point of view of someone intelligently optimizing the world to be a better, more moral place_. HPMOR let me look through the eyes of someone who deeply cares about the world and who tries to do the most good that they can. The _experience_ counts.

You’ll notice that CS-151 doesn’t start off with a [category theoretic-motivation of functional programming](https://bartoszmilewski.com/2014/10/28/category-theory-for-programmers-the-preface/) in Scheme, with armchair theorizing about loop invariants, parametric polymorphism, and time complexity. There are labs. You experience it yourself. That’s how the beauty of computer science _sticks to you_. 

As far as I know, HPMOR is the media which imparts the strongest "lived experience" of _gut-level caring about hammering the world into better shape_. 

# On Foolishness

Second, in 2016, I was enthusiastic, optimistic, and hard-working. I was willing to swim against social convention. I was also foolish.

By “foolish”, I don’t quite mean “I did pointless things.” I mean: “My cognitive algorithm was not very good, and _so_ I did pointless things.” By analogy, suppose it’s 2026, and you’re doing research with the assistance of a machine learning model. Given a hypothesis, the model goes off and finds evidence. But suppose that the model _anchors_ on the first evidence it finds: Some study supports the idea, and then the model selectively looks for _more evidence for its existing beliefs_! Wouldn’t this just be _so annoying and stupid_? 

In some parts of your life, you are like this. Yes, _you_. Our brains regularly make embarrassing, biased mistakes. For example, I stayed in a relationship for a year too long because I was not honest with myself about how I felt. 

In 2014, I scrolled past a Facebook news feed article in which Elon Musk worried about extinction from AI. I rolled my eyes—“Elon, AI is great, you have no idea what you’re talking about.” And so I kept scrolling.[^laugh] 

[^laugh]: If someone made a biopic about me, this is where the canned laugh track would play.

The mistake was that I had a strong, knee-jerk opinion about something I’d never even thought about. In 2018, I reconsidered the topic. I ignored the news articles and sought out the best arguments from each side of the debate. I concluded that my first impression was _totally, confidently wrong_. What an easy way to waste four years. I’m now finishing my dissertation on reducing extinction risk from AI, [publishing](https://papers.nips.cc/paper/2020/file/f50a6c02a3fc5a3a5d4d9391f05f3efc-Paper.pdf) [papers](https://arxiv.org/pdf/1912.01683.pdf) in top AI conferences. 

My cognitive algorithm was not that great, and so I made many costly mistakes. Now I make fewer. 

---

What, pray tell, does this have to do with Harry Potter? HPMOR channels someone who tries to improve their thinking with the power and insight granted by behavioral economics and cognitive psychology, all in pursuit of worthy goals. The book gave me a sense that _more is possible_, in a way that seems hard to pick up from a textbook.[^psych] 

[^psych]: I took cog-psych classes at Grinnell. They were evidently insufficient for this purpose: I didn’t even realize that I should try to do better!

HPMOR demonstrates altruistic fierceness: How can I make the future _as bright as possible_? How can I make the _best_ out of my current situation? What kinds of thinking help me arrive at the truth _as quickly as possible_? What do I think I know, and why do I think I know it? What would reality look like if my most cherished beliefs were _wrong_?

In the real world, we may stand at the relative beginning of a bright and long human history. But to ensure that humanity _has_ a future, to make things go _right_—that may require finding the truth as quickly as possible. That may require clever schemes for doing the most good we can, whatever we can. That may require altruistic fierceness.[^fierce] 

[^fierce]: See: the [Effective Altruism](https://www.effectivealtruism.org/) movement.

Taken together, _caring deeply about maximizing human fulfillment_ and _improving my cognitive algorithms_ changed my life. I don’t know if this particular book will have this particular effect on you. For example, you might not be primarily altruistically motivated on reflection. That’s fine. I think you may still selfishly benefit from this viewpoint and skillset. 

HPMOR isn’t the only way to win these benefits. But I think it’s quite good for some people, which should make it worth your time to try 5–10 chapters. I hope you benefit as much as I did. 

<hr/>


You can find the book at [`www.hpmor.com`](http://www.hpmor.com) (I recommend the [PDF version](https://cdn.jsdelivr.net/gh/rjl20/hpmor@0c10d2e8b6bd68e88fd2fc6e6b233140917e7314/out/hpmor.pdf)). You can find the unofficial, very good podcast reading [on Spotify](https://open.spotify.com/playlist/4JQT5fmI8EJBiISLX06sZt?si=d4924f208e96429d). You can find me at [`alex@turntrout.com`](mailto:alex@turntrout.com).